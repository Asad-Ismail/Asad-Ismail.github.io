<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deployment on Asad Ismail</title>
    <link>https://Asad-Ismail.github.io/tags/deployment/</link>
    <description>Recent content in Deployment on Asad Ismail</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 11 Jan 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://Asad-Ismail.github.io/tags/deployment/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ML Model Deployment on AWS: A Practical Guide</title>
      <link>https://Asad-Ismail.github.io/posts/mlmodeldeployment/</link>
      <pubDate>Sat, 11 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://Asad-Ismail.github.io/posts/mlmodeldeployment/</guid>
      <description>&lt;h1 id=&#34;ml-model-deployment-on-aws&#34;&gt;&#xA;  ML Model Deployment on AWS&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#ml-model-deployment-on-aws&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Most ML projects should start with batch processing. It is cheaper, easier to debug, and forces you to think about whether you actually need real-time predictions. Only move to real-time endpoints when batch genuinely does not work for your use case.&lt;/p&gt;&#xA;&lt;p&gt;This guide covers four deployment patterns with working AWS code.&lt;/p&gt;&#xA;&lt;h2 id=&#34;four-deployment-patterns&#34;&gt;&#xA;  Four Deployment Patterns&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#four-deployment-patterns&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Pick based on your latency and cost requirements:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
