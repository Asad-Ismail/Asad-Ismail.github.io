<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Asad Ismail</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Asad Ismail</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 11 Jan 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building an End-to-End ML Pipeline with Modern Tools</title>
      <link>http://localhost:1313/posts/building-ml-pipeline/</link>
      <pubDate>Sat, 11 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/building-ml-pipeline/</guid>
      <description>Building an End-to-End ML Pipeline with Modern Tools Link to heading Production machine learning requires more than just training models—it needs robust, automated pipelines that handle data ingestion, preprocessing, training, validation, and deployment. This post demonstrates building a complete ML pipeline using modern MLOps tools.&#xA;What is an ML Pipeline? Link to heading An ML pipeline orchestrates the entire machine learning lifecycle:&#xA;Raw Data → Ingestion → Preprocessing → Feature Engineering → Training → Validation → Deployment → Monitoring → Feedback Loop Key benefits:</description>
    </item>
    <item>
      <title>ML Model Deployment: Strategies and Best Practices</title>
      <link>http://localhost:1313/posts/mlmodeldeployment/</link>
      <pubDate>Sat, 11 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/mlmodeldeployment/</guid>
      <description>ML Model Deployment: Strategies and Best Practices Link to heading Deploying machine learning models to production is a critical step in the ML lifecycle that often receives less attention than model development. A well-trained model is useless if it cannot be reliably served to users or systems in production environments. In this post, we&amp;rsquo;ll explore key deployment strategies and best practices for production ML systems.&#xA;Common Deployment Strategies Link to heading 1.</description>
    </item>
    <item>
      <title>PyTorch vs TensorFlow: Choosing the Right Framework for Production</title>
      <link>http://localhost:1313/posts/pytorch-vs-tensorflow/</link>
      <pubDate>Sat, 11 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/pytorch-vs-tensorflow/</guid>
      <description>PyTorch vs TensorFlow: Choosing the Right Framework for Production Link to heading When building production machine learning systems, choosing the right deep learning framework is a critical decision that impacts development velocity, model performance, and operational complexity. PyTorch and TensorFlow dominate the landscape, each with distinct strengths and trade-offs. This post compares both frameworks from a production perspective.&#xA;Architecture and Philosophy Link to heading PyTorch: Pythonic and Dynamic Link to heading PyTorch embraces Python&amp;rsquo;s design philosophy with dynamic computation graphs:</description>
    </item>
  </channel>
</rss>
